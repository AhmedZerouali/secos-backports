{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal being to study backports in an ecosystem, we will focus on:\n",
    "\n",
    " - Packages being required by other packages (otherwise, there is no need to backport updates!);\n",
    " - Packages being sufficiently required by other packages (see above);\n",
    " - Required packages being active (abandonned packages are unlikely to deploy backports);\n",
    " - Dependent packages being active (one can expect packages abandonned for years to still rely on very old versions of their dependencies)\n",
    " \n",
    "This notebook aims to select required and dependent packages based on some thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import tqdm\n",
    "\n",
    "from version import Version\n",
    "from parsers import parse_or_empty\n",
    "from parsers import NPMParser\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIG_SIZE = (6, 4)\n",
    "PALETTE = seaborn.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_releases = (\n",
    "    pandas.read_csv('../data-raw/releases.csv.gz')\n",
    "    .assign(date=lambda d: pandas.to_datetime(d['date'], infer_datetime_format=True))\n",
    "    .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies = (\n",
    "    pandas.read_csv('../data-raw/dependencies.csv.gz')\n",
    "    .dropna()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert versions to semver syntax, and remove those that cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_releases[['major', 'minor', 'patch', 'misc']] = (\n",
    "    df_releases['version'].str.extract(Version.RE, expand=True)\n",
    ")\n",
    "df_releases[['major', 'minor', 'patch']] = df_releases[['major', 'minor', 'patch']].astype(float)\n",
    "\n",
    "# Remove non-compliant versions\n",
    "n = len(df_releases)\n",
    "df_releases = df_releases.dropna(subset=['major', 'minor', 'patch'])\n",
    "print(n - len(df_releases), 'non-compliant versions dropped (total was {})'.format(n))\n",
    "\n",
    "# Remove prereleases and duplicates, keep first\n",
    "n = len(df_releases)\n",
    "df_releases = (\n",
    "    df_releases\n",
    "    [lambda d: d['misc'].isnull()]\n",
    "    .sort_values(['package', 'date'])\n",
    "    .drop_duplicates(['package', 'major', 'minor', 'patch'], keep='last')\n",
    "    .drop(columns=['misc'])\n",
    ")\n",
    "print(n - len(df_releases), 'prerelease and duplicated versions dropped (total was {})'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select a set of required and dependent packages, we remove packages that were not active for some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_ACTIVITY = df_releases.date.max() - pandas.to_timedelta('365 days')\n",
    "LAST_ACTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Packages and releases:', len(df_releases.drop_duplicates('package')), len(df_releases))\n",
    "print('Active packages:', len(df_releases[lambda d: d['date'] >= LAST_ACTIVITY].drop_duplicates('package')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we consider only dependencies from the latest version of each package. This will allow us to quantify the number of dependents for each required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies = (\n",
    "    df_dependencies\n",
    "    .merge(\n",
    "        (\n",
    "            df_releases\n",
    "            [['package', 'version', 'date']]\n",
    "            [lambda d: d['date'] >= LAST_ACTIVITY]\n",
    "            .sort_values('date')\n",
    "            .drop_duplicates('package', keep='last')\n",
    "        ),\n",
    "        how='inner',\n",
    "        left_on=['source', 'version'],\n",
    "        right_on=['package', 'version']\n",
    "    )\n",
    "    .drop(columns=['package'])\n",
    "    [lambda d: d['target'].isin(df_releases.package)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = matplotlib.pyplot.subplots()\n",
    "fig.set_size_inches(FIG_SIZE)\n",
    "\n",
    "data = (\n",
    "    df_dependencies\n",
    "    .groupby(['target'], sort=False)\n",
    "    .agg({'source': 'count'})\n",
    "    .sort_values('source', ascending=False)\n",
    "    .assign(cum_source=lambda d: d['source'].cumsum())\n",
    "    .assign(cum_target=lambda d: d.assign(n=1).n.cumsum())\n",
    "    # Make them proportional\n",
    "    .assign(\n",
    "        cum_source=lambda d: d['cum_source'] / d['cum_source'].iloc[-1],\n",
    "        cum_target=lambda d: d['cum_target'] / d['cum_target'].iloc[-1],\n",
    "    )\n",
    ")\n",
    "\n",
    "data.set_index('cum_target')[['cum_source']].plot(ax=ax)\n",
    "\n",
    "ax.legend().remove()\n",
    "ax.set(\n",
    "    xlabel='cumulative proportion of required packages',\n",
    "    xlim=(0, 1),\n",
    "    ylabel='cumulative proportion of dependent packages',\n",
    "    ylim=(0, 1),\n",
    ")\n",
    "\n",
    "ax.hlines(0.8, 0, 1, color='r', alpha=0.5, linestyles='dashed')\n",
    "ax.vlines(0.2, 0, 1, color='r', alpha=0.5, linestyles='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must decide on how to select packages that will be kept as \"required\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('cum_source >= 0.8').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('cum_target >= 0.2').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('cum_target >= 0.1').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('source <= 20').iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keeping 10% of all required packages means we have at least 10 dependent packages. Keeping 20 dependent packages implies ignoring nearly 95% of all required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_REQ = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrieve the list of these required packages, and we identify for all their releases their order and type.\n",
    "This will be our dataset of \"required packages\". Based on these packages, we will then create a dataset of \"dependent packages\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required = data[lambda d: d['source'] >= MIN_REQ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for name, group in tqdm.tqdm(df_releases[lambda d: d['package'].isin(required)].groupby('package', sort=False)):\n",
    "    group = (\n",
    "        group\n",
    "        # Rank by version\n",
    "        .sort_values(['major', 'minor', 'patch'])\n",
    "        .assign(\n",
    "            rank=lambda d: d.assign(N=1).N.cumsum(),\n",
    "            kinitial=lambda d: d['major'].shift(1).isnull(),\n",
    "            kmajor=lambda d: (d['major'] - d['major'].shift(1)).clip(0, 1).astype(bool),\n",
    "            kminor=lambda d: (d['minor'] - d['minor'].shift(1)).clip(0, 1).astype(bool),\n",
    "            kpatch=lambda d: (d['patch'] - d['patch'].shift(1)).clip(0, 1).astype(bool),\n",
    "        )\n",
    "        .assign(kind=lambda d: d[['kinitial', 'kmajor', 'kminor', 'kpatch']].idxmax(axis=1))\n",
    "        .replace({'kind': {'kinitial': 'initial', 'kmajor': 'major', 'kminor': 'minor', 'kpatch': 'patch'}})        \n",
    "        .drop(columns=['kinitial', 'kmajor', 'kminor', 'kpatch'])\n",
    "        \n",
    "        # Rank by date\n",
    "        .sort_values(['date', 'rank'])  # Use rank if versions are distributed on the same day (e.g. imports)\n",
    "        .assign(rank_date=lambda d: d.assign(N=1).N.cumsum())\n",
    "        \n",
    "        # Detect backported releases\n",
    "        .assign(hrank=lambda d: d['rank'].expanding().max())\n",
    "        .assign(hmajor=lambda d: d['major'].expanding().max())\n",
    "        # Identify backported releases. The value corresponds to the highest rank seen so far...\n",
    "        #.assign(backported=lambda d: d['hrank'].where(d['rank'] < d['hrank'], pandas.np.nan))\n",
    "        .assign(backported=lambda d: d['hrank'].where(d['major'] < d['hmajor'], pandas.np.nan))\n",
    "        .drop(columns=['hrank', 'hmajor'])\n",
    "        # ... but it could be the case that the backport is released before its \"origin\", so we check\n",
    "        # the date of rank + 1 as well, and take the closest date.\n",
    "        .pipe(lambda df: \n",
    "            df.merge(\n",
    "                df[['date', 'rank']], \n",
    "                how='left', \n",
    "                left_on=['backported'], \n",
    "                right_on=['rank'],\n",
    "                suffixes=('', '_previous'),\n",
    "            )\n",
    "            .merge(\n",
    "                df[['date', 'rank']].assign(rank=lambda d: d['rank'] - 1),\n",
    "                how='left',\n",
    "                left_on=['backported'],\n",
    "                right_on=['rank'],\n",
    "                suffixes=('', '_next'),\n",
    "            )\n",
    "            .assign(rank_next=lambda d: d['rank_next'] + 1)\n",
    "            # Take closest date\n",
    "            .assign(backported_from=lambda d:\n",
    "                d['rank_previous'].where(abs(d['date'] - d['date_previous']) <= abs(d['date'] - d['date_next']), d['rank_next'])\n",
    "            )\n",
    "        )\n",
    "        .drop(columns=['date_previous', 'date_next', 'rank_previous', 'rank_next'])\n",
    "        .assign(backported=lambda d: ~d['backported'].isnull())\n",
    "    )\n",
    "    \n",
    "    data.append(group)\n",
    "    \n",
    "df_required = (\n",
    "    pandas.concat(data)\n",
    "    .sort_values(['package', 'rank'])\n",
    "    [['package', 'version', 'major', 'minor', 'patch', 'rank', 'date', 'rank_date', 'backported', 'backported_from']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_required.query('package == \"vue-awesome\"').iloc[25:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "df_required.to_csv('../data/required.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's collect data for dependent packages. We'll convert dependency constraint to intervals, and then we look at what is the latest and highest versions being accepted by that constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents = (\n",
    "    df_dependencies\n",
    "    [lambda d: d['target'].isin(required)]\n",
    ")\n",
    "\n",
    "intervals = dict() \n",
    "parser = NPMParser()\n",
    "\n",
    "for constraint in tqdm.tqdm(df_dependents.constraint.drop_duplicates()):\n",
    "    interval = parse_or_empty(parser, constraint)\n",
    "    d = {'interval': interval}\n",
    "    \n",
    "    if interval.is_empty():\n",
    "        d['empty'] = True\n",
    "        d['major'] = d['minor'] = d['patch'] = d['dev'] = False\n",
    "    else:\n",
    "        base = interval.lower \n",
    "        d['empty'] = False\n",
    "        d['major'] = Version(float('inf'), 0, 0) in interval\n",
    "        d['minor'] = Version(base.major, float('inf'), 0) in interval\n",
    "        d['patch'] = Version(base.major, base.minor, float('inf')) in interval\n",
    "        d['dev'] = Version(1, 0, 0) > interval\n",
    "        \n",
    "    intervals[constraint] = d\n",
    "    \n",
    "# Are all intervals equal to their enclosure? (i.e. are there \"gaps\"?)\n",
    "len([i['interval'] for i in intervals.values() if i['interval'] != i['interval'].enclosure()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highest accepted releases\n",
    "data = []\n",
    "\n",
    "for target, group in tqdm.tqdm(df_dependents.groupby('target', as_index=False, sort=False)):\n",
    "    releases = (\n",
    "        df_required[lambda d: d['package'] == target]\n",
    "        .assign(version=lambda d: d['version'].apply(lambda v: Version(v)))\n",
    "        .sort_values('rank', ascending=False)\n",
    "    )\n",
    "    \n",
    "    for constraint, group in group.groupby('constraint', as_index=False, sort=False):\n",
    "        d = intervals[constraint]\n",
    "        interval = d['interval']\n",
    "        selected = None\n",
    "        \n",
    "        for release in releases.itertuples():\n",
    "            if release.version in interval:\n",
    "                selected = release.rank\n",
    "                break  # Because they are sorted by descending rank\n",
    "        else:\n",
    "            selected = pandas.np.nan\n",
    "            \n",
    "        data.append((\n",
    "            group.assign(\n",
    "                interval=str(interval),\n",
    "                selected=selected,\n",
    "                c_empty=d['empty'],\n",
    "                c_dev=d['dev'],\n",
    "                c_major=d['major'],\n",
    "                c_minor=d['minor'],\n",
    "                c_patch=d['patch'],\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "df_dependents = (\n",
    "    pandas.concat(data)\n",
    "    .sort_values(['source', 'target'])\n",
    "    [['source', 'version', 'date', 'target', 'constraint', 'interval', 'selected', 'c_empty', 'c_dev', 'c_major', 'c_minor', 'c_patch']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dependents.to_csv('../data/dependents.csv.gz', index=False, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
